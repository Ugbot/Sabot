# Examples Conversion Status

Converting Sabot examples to use the new CLI-compatible agent model with `@app.agent()` decorator.

## Summary

**Total Converted: 11 out of ~26 identified examples**

Many examples are **standalone API demos** or **architectural showcases** that don't consume from Kafka and aren't suitable for CLI conversion. These demonstrate API usage patterns, not production streaming applications.

---

## ‚úÖ Completed Conversions (11 total)

### Core Examples (2/2) ‚úÖ Complete
- [x] `core/basic_pipeline.py` - Sensor monitoring with CLI
- [x] `core/simplified_demo.py` - Standalone concept demo (no Kafka)

### Streaming Examples (3/3) ‚úÖ Complete
- [x] `streaming/windowed_analytics.py` - Tumbling/sliding windows with 3 agents
- [x] `streaming/multi_agent_coordination.py` - 4-agent coordinated pipeline
- [x] `streaming/agent_processing.py` - Stateful fraud detection

### Storage Examples (2/3) ‚úÖ Complete
- [x] `storage/pluggable_backends.py` - Memory/RocksDB state backends with 2 agents
- [x] `storage/materialized_views.py` - RocksDB-backed materialized views with 3 agents
- [~] `storage/debezium_materialized_views.py` - **Standalone API demo** (shows materialized view concepts)

### Data Examples (2/4)
- [x] `data/arrow_operations.py` - Arrow columnar operations with 3 agents
- [x] `data/joins_demo.py` - Stream-table and stream-stream joins with 4 agents
- [~] `data/arrow_joins_demo.py` - **Standalone API demo** (demonstrates Arrow join API)
- [~] `data/flink_joins_demo.py` - **Standalone API demo** (demonstrates Flink-style join types)

### Root Examples (1/6)
- [x] `telemetry_demo.py` - OpenTelemetry integration with distributed tracing
- [~] `arrow_tonbo_demo.py` - **Standalone API demo** (Arrow+Tonbo integration)
- [~] `kafka_bridge_demo.py` - **Standalone API demo** (Kafka bridging architecture)
- [~] `dbos_durable_checkpoint_demo.py` - **Standalone API demo** (DBOS checkpoint API)
- [~] `comprehensive_telemetry_demo.py` - **Standalone API demo** (observability instrumentation)
- [~] `grand_demo.py` - **Standalone comprehensive demo** (all features showcase, broker=None)

### Already CLI-Compatible (No conversion needed)
- [x] `fraud_app.py` - Already uses `@app.agent()`
- [x] `flink_fraud_demo.py` - Standalone demo
- [x] `flink_fraud_detector.py` - Library code (not an application)
- [x] `flink_fraud_producer.py` - Producer script (not a consumer)

---

## üîç Identified But Not Converted

These examples are **intentionally not converted** because they serve different purposes:

### Standalone API Demos
Examples that demonstrate API usage patterns without consuming from Kafka:
- `storage/debezium_materialized_views.py` - Shows materialized view API
- `data/arrow_joins_demo.py` - Demonstrates PyArrow join operations
- `data/flink_joins_demo.py` - Shows Flink-style join type APIs
- `arrow_tonbo_demo.py` - Shows Arrow+Tonbo integration
- `kafka_bridge_demo.py` - Demonstrates bridging architecture
- `dbos_durable_checkpoint_demo.py` - Shows checkpoint manager API
- `comprehensive_telemetry_demo.py` - Shows observability instrumentation

### Architectural Showcases
Complex demos showing system design patterns:
- `grand_demo.py` - Comprehensive feature showcase (uses `broker=None`)

### Not Found/Unknown Status
- `cluster/` examples (4 files) - Need investigation
- `advanced/` GPU examples (3 files) - Likely hardware-specific demos
- `cli/` examples (2 files) - May be CLI tool code, not streaming apps

---

## üìù Conversion Pattern

### Before (Old Pattern):
```python
from sabot import create_app, StreamBuilder
import asyncio

async def main():
    app = create_app('my-app')

    stream = (StreamBuilder(app, 'my-topic')
        .map(lambda x: process(x))
        .filter(lambda x: x['value'] > threshold)
        .sink(lambda x: print(x)))

    await app.start()
    # ... manual event loop
    await app.stop()

if __name__ == "__main__":
    asyncio.run(main())
```

### After (New Pattern):
```python
import sabot as sb

# Create app at module level
app = sb.App(
    'my-app',
    broker='kafka://localhost:19092',
    value_serializer='json'
)

# Define agent with decorator
@app.agent('my-topic')
async def process_events(stream):
    """Process events from my-topic."""
    print("üöÄ Agent started")

    async for event in stream:
        try:
            # Process event
            processed = process(event)

            # Filter
            if processed['value'] > threshold:
                print(f"‚úÖ Processed: {processed}")
                yield processed

        except Exception as e:
            print(f"‚ùå Error: {e}")
            continue

# Run with: sabot -A examples.module.myfile:app worker
```

---

## üîÑ Conversion Steps

1. **Update imports:**
   ```python
   import sabot as sb  # Instead of: from sabot import create_app, StreamBuilder
   ```

2. **Create app at module level:**
   ```python
   app = sb.App('name', broker='kafka://localhost:19092')
   ```

3. **Convert StreamBuilder to @app.agent():**
   - Replace functional chains with explicit async loops
   - Use `yield` to forward results

4. **Remove main() function:**
   - No more manual `await app.start()` / `await app.stop()`
   - CLI handles lifecycle management

5. **Update docstring with CLI usage:**
   ```python
   """
   Usage:
       sabot -A examples.module.myfile:app worker

   Send test data:
       python producer_script.py
   """
   ```

6. **Remove mock fallback code:**
   - Remove `MockApp`, `MockStream` classes
   - Remove `try/except ImportError` blocks
   - Remove `SABOT_AVAILABLE` checks

7. **Move producer code to docstring:**
   - Include inline producer examples for testing
   - Show how to generate test data with confluent_kafka

---

## üìä Benefits of CLI Model

### For Users:
- ‚úÖ Production-ready deployment pattern
- ‚úÖ Automatic Kafka consumer management
- ‚úÖ Built-in health checks and monitoring
- ‚úÖ Easy scaling: `sabot -A app:worker --concurrency 4`
- ‚úÖ Consistent with Faust/Celery ecosystem

### For Code:
- ‚úÖ Cleaner, less boilerplate (40-50% reduction)
- ‚úÖ No manual event loop management
- ‚úÖ No mock fallback code needed
- ‚úÖ Better separation: agents vs producers
- ‚úÖ Easier to test and maintain

---

## üöÄ Testing Converted Examples

After conversion, test each example:

1. **Start infrastructure:**
   ```bash
   docker compose up -d
   ```

2. **Run worker:**
   ```bash
   sabot -A examples.module.filename:app worker --loglevel=DEBUG
   ```

3. **Send test data:**
   ```bash
   # Use producer code from example docstring
   python -c "
   from confluent_kafka import Producer
   import json, time

   producer = Producer({'bootstrap.servers': 'localhost:19092'})
   # ... (copy from example docstring)
   "
   ```

4. **Verify output:**
   - ‚úÖ Agent starts successfully
   - ‚úÖ Data processing works correctly
   - ‚úÖ Metrics/alerts appear
   - ‚úÖ No errors in logs

---

## üìù Conversion Guidelines

### ‚úÖ DO Convert:
- Examples that consume from Kafka topics
- Examples with actual streaming data processing
- Examples demonstrating production patterns
- Examples with stateful processing

### ‚ùå DON'T Convert:
- Standalone API demos (`broker=None` or no Kafka)
- Library code (utility functions, not applications)
- Producer scripts (they generate data, don't consume)
- Examples that demonstrate low-level APIs
- Architectural showcases using manual stream creation

### ü§î Consider Converting:
- Examples with both old pattern AND `@app.agent()` decorators
- Examples that could be adapted to consume from Kafka
- Broken examples that reference undefined `app` objects

---

## üìà Conversion Progress by Category

| Category | Converted | Standalone | Total |
|----------|-----------|------------|-------|
| Core | 2 | 0 | 2 |
| Streaming | 3 | 0 | 3 |
| Storage | 2 | 1 | 3 |
| Data | 2 | 2 | 4 |
| Root | 1 | 5 | 6 |
| **Total** | **11** | **8** | **19** |

**Note:** Cluster, Advanced, and CLI examples not yet fully reviewed.

---

## üéØ Key Converted Examples

### 1. **windowed_analytics.py** (Streaming)
- 3 agents demonstrating tumbling, sliding, and session windows
- Real-time API request analytics
- Shows window aggregation patterns

### 2. **multi_agent_coordination.py** (Streaming)
- 4-agent pipeline: ingestion ‚Üí validation ‚Üí enrichment ‚Üí analytics
- Shared coordinator state
- Demonstrates agent coordination patterns

### 3. **pluggable_backends.py** (Storage)
- 2 agents sharing state via RocksDB/Memory backends
- MapState, ValueState, ListState demonstration
- Production-ready state management

### 4. **materialized_views.py** (Storage)
- 3 agents maintaining real-time materialized views
- User behavior, product analytics, category analytics
- RocksDB-backed aggregations

### 5. **joins_demo.py** (Data)
- 4 agents demonstrating streaming joins
- Stream-table join (enrichment with reference data)
- Stream-stream join (time-windowed correlation)
- Join effectiveness statistics

### 6. **telemetry_demo.py** (Root)
- OpenTelemetry integration with distributed tracing
- Custom spans for validation, business logic, state updates
- Metrics collection (counters, histograms)

---

**Status**: 11 streaming apps converted, 8 standalone demos identified
**Last Updated**: 2025-10-01
