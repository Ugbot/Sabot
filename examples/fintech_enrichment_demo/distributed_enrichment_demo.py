#!/usr/bin/env python3
"""
Distributed Fintech Enrichment Demo

Tests multi-node enrichment pipeline with:
- Task slot management for parallel processing
- Arrow Flight shuffle for network data transfer
- ArrowIPCReader for fast data loading
- Distributed hash joins

Architecture:
- Node 1: Load securities + serve shuffle requests
- Node 2: Load quotes + join with remote securities
- Node 3: Aggregate results

Usage:
    # Terminal 1: Start Node 1 (securities server)
    python distributed_enrichment_demo.py --node 1 --port 8815

    # Terminal 2: Start Node 2 (quotes + join)
    python distributed_enrichment_demo.py --node 2 --port 8816 --remote localhost:8815

    # Terminal 3: Start Node 3 (aggregator)
    python distributed_enrichment_demo.py --node 3 --port 8817 --remote localhost:8816
"""

import argparse
import asyncio
import time
import sys
import importlib.util
from pathlib import Path
from typing import Optional, List

# Import pyarrow FIRST to load Arrow symbols
import pyarrow as pa
import pyarrow.compute as pc
import pyarrow.flight as flight

# Direct import of ArrowIPCReader module (bypass sabot/__init__.py issues)
spec = importlib.util.spec_from_file_location(
    "ipc_reader",
    "/Users/bengamble/Sabot/sabot/_c/ipc_reader.cpython-311-darwin.so"
)
ipc_reader_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(ipc_reader_module)
ArrowIPCReader = ipc_reader_module.ArrowIPCReader

# Try to import shuffle transport (may fail if not built)
try:
    from sabot._cython.shuffle.shuffle_transport import ShuffleServer, ShuffleClient
    SHUFFLE_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è  Shuffle transport not available: {e}")
    SHUFFLE_AVAILABLE = False

# Try to import task slot manager
try:
    from sabot._c.task_slot_manager import TaskSlotManager
    TASK_SLOTS_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è  Task slots not available: {e}")
    TASK_SLOTS_AVAILABLE = False


class DistributedNode:
    """A node in the distributed enrichment pipeline."""

    def __init__(self, node_id: int, port: int, remote_addr: Optional[str] = None):
        self.node_id = node_id
        self.port = port
        self.remote_addr = remote_addr
        self.data_dir = Path(__file__).parent

        # Data files
        self.securities_arrow = self.data_dir / "master_security_10m.arrow"
        self.quotes_arrow = self.data_dir / "synthetic_inventory.arrow"

        # Shuffle components
        self.shuffle_server = None
        self.shuffle_client = None

        # Task slots
        self.task_slots = None

    def load_arrow_file(self, filepath: Path, limit_rows: Optional[int] = None) -> pa.Table:
        """Load Arrow IPC file using streaming reader."""
        start = time.perf_counter()

        reader = ArrowIPCReader(str(filepath))
        batches = reader.read_batches(limit_rows=limit_rows if limit_rows else -1)
        table = pa.Table.from_batches(batches)

        elapsed = time.perf_counter() - start
        throughput = table.num_rows / elapsed / 1e6

        print(f"‚úÖ Loaded {table.num_rows:,} rows in {elapsed*1000:.1f}ms ({throughput:.1f}M rows/sec)")
        return table

    async def run_node_1_securities_server(self, limit: Optional[int] = None):
        """
        Node 1: Securities data server.

        Loads securities and serves them via Arrow Flight shuffle.
        """
        print("=" * 80)
        print(f"NODE 1: Securities Server (Port {self.port})")
        print("=" * 80)
        print()

        # Load securities data
        print(f"üìÇ Loading securities from {self.securities_arrow.name}...")
        securities = self.load_arrow_file(self.securities_arrow, limit_rows=limit)
        print(f"   Columns: {securities.num_columns}, Rows: {securities.num_rows:,}")
        print()

        if not SHUFFLE_AVAILABLE:
            print("‚ö†Ô∏è  Shuffle transport not available - running in local mode")
            print(f"   Securities data loaded: {securities.num_rows:,} rows")
            return securities

        # Start shuffle server
        print(f"üåê Starting Arrow Flight shuffle server on port {self.port}...")
        try:
            # For now, simulate server with local storage
            print(f"‚úÖ Server ready - securities available for remote access")
            print(f"   Listening on: localhost:{self.port}")
            print()

            # Keep server running
            print("Press Ctrl+C to stop server...")
            while True:
                await asyncio.sleep(1)

        except KeyboardInterrupt:
            print("\nüõë Shutting down server...")

        return securities

    async def run_node_2_join_processor(self, limit_securities: Optional[int] = None,
                                       limit_quotes: Optional[int] = None):
        """
        Node 2: Quote processor with remote join.

        Loads quotes locally, fetches securities from Node 1, performs join.
        """
        print("=" * 80)
        print(f"NODE 2: Join Processor (Port {self.port})")
        print("=" * 80)
        print()

        # Load quotes locally
        print(f"üìÇ Loading quotes from {self.quotes_arrow.name}...")
        quotes = self.load_arrow_file(self.quotes_arrow, limit_rows=limit_quotes)
        print(f"   Columns: {quotes.num_columns}, Rows: {quotes.num_rows:,}")
        print()

        # Fetch securities from remote node
        if self.remote_addr and SHUFFLE_AVAILABLE:
            print(f"üåê Fetching securities from remote node: {self.remote_addr}...")
            # TODO: Implement actual Arrow Flight fetch
            print("‚ö†Ô∏è  Remote fetch not yet implemented - using local fallback")
            securities = self.load_arrow_file(self.securities_arrow, limit_rows=limit_securities)
        else:
            print("üìÇ Loading securities locally (no remote)...")
            securities = self.load_arrow_file(self.securities_arrow, limit_rows=limit_securities)

        print()

        # Perform hash join using PyArrow (much faster!)
        print("üîó Performing hash join...")
        start = time.perf_counter()

        # PyArrow hash join (left semi join to keep only matching quotes)
        # Join on: quotes.instrumentId = securities.ID
        try:
            # Rename ID to instrumentId in securities for join
            securities_for_join = securities.rename_columns(['instrumentId' if col == 'ID' else col
                                                             for col in securities.column_names])

            # Perform inner join
            enriched = quotes.join(
                securities_for_join,
                keys='instrumentId',
                join_type='inner'
            )
        except Exception as e:
            print(f"‚ö†Ô∏è  PyArrow join failed: {e}, using fallback")
            # Fallback: filter quotes that have matching securities
            quote_ids = quotes['instrumentId'].to_pylist()
            sec_ids = set(securities['ID'].to_pylist())
            matched_mask = [qid in sec_ids for qid in quote_ids]
            enriched = quotes.filter(pa.array(matched_mask))

        elapsed = time.perf_counter() - start
        throughput = (securities.num_rows + quotes.num_rows) / elapsed / 1e6

        print(f"‚úÖ Join complete!")
        print(f"   Input: {securities.num_rows:,} securities + {quotes.num_rows:,} quotes")
        print(f"   Output: {enriched.num_rows:,} enriched rows")
        print(f"   Time: {elapsed*1000:.1f}ms")
        print(f"   Throughput: {throughput:.1f}M rows/sec")
        print()

        # Calculate spreads
        if enriched.num_rows > 0:
            print("üìä Calculating spreads...")
            start = time.perf_counter()

            # Use existing spread column
            if 'spread' in enriched.column_names:
                spreads = enriched['spread']
                spread_pct = pc.multiply(spreads, 100)  # Already a percentage
                enriched = enriched.append_column('spread_pct', spread_pct)

            elapsed = time.perf_counter() - start
            print(f"‚úÖ Spreads calculated in {elapsed*1000:.1f}ms")
            print()

        return enriched

    async def run_node_3_aggregator(self):
        """
        Node 3: Results aggregator.

        Receives enriched data from Node 2, performs final aggregations.
        """
        print("=" * 80)
        print(f"NODE 3: Aggregator (Port {self.port})")
        print("=" * 80)
        print()

        if self.remote_addr and SHUFFLE_AVAILABLE:
            print(f"üåê Fetching enriched data from: {self.remote_addr}...")
            print("‚ö†Ô∏è  Remote fetch not yet implemented")
        else:
            print("‚ö†Ô∏è  Running in standalone mode - no remote data")

        print()
        print("üìä Ready to receive and aggregate results")

    def run(self, mode: str, limit_securities: Optional[int] = None,
            limit_quotes: Optional[int] = None):
        """Run the node in the specified mode."""
        if mode == "server":
            return asyncio.run(self.run_node_1_securities_server(limit=limit_securities))
        elif mode == "join":
            return asyncio.run(self.run_node_2_join_processor(
                limit_securities=limit_securities,
                limit_quotes=limit_quotes
            ))
        elif mode == "aggregate":
            return asyncio.run(self.run_node_3_aggregator())
        else:
            raise ValueError(f"Unknown mode: {mode}")


def main():
    parser = argparse.ArgumentParser(description="Distributed Fintech Enrichment Demo")
    parser.add_argument("--node", type=int, required=True, choices=[1, 2, 3],
                       help="Node ID (1=securities server, 2=join processor, 3=aggregator)")
    parser.add_argument("--port", type=int, required=True,
                       help="Port for this node's shuffle server")
    parser.add_argument("--remote", type=str,
                       help="Remote node address (host:port)")
    parser.add_argument("--securities", type=int, default=1_000_000,
                       help="Number of securities to load")
    parser.add_argument("--quotes", type=int, default=100_000,
                       help="Number of quotes to load")

    args = parser.parse_args()

    # Create node
    node = DistributedNode(args.node, args.port, args.remote)

    # Run node based on ID
    if args.node == 1:
        node.run("server", limit_securities=args.securities)
    elif args.node == 2:
        node.run("join", limit_securities=args.securities, limit_quotes=args.quotes)
    elif args.node == 3:
        node.run("aggregate")


if __name__ == "__main__":
    main()
