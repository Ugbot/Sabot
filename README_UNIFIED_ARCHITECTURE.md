# Sabot Unified Architecture

## TL;DR

Sabot now has a **unified architecture** with a single entry point instead of 4-5 separate projects.

```python
from sabot import Sabot

# One engine, all functionality
engine = Sabot(mode='local')

# Stream processing
stream = engine.stream.from_kafka('topic').filter(lambda b: b.column('x') > 10)

# SQL processing  
result = engine.sql("SELECT * FROM table WHERE x > 10")

# Graph processing
matches = engine.graph.cypher("MATCH (a)-[:KNOWS]->(b) RETURN a, b")

# Clean shutdown
engine.shutdown()
```

---

## What Changed

### Before: Fragmented (4-5 Projects)

```
‚ùå Multiple entry points
‚ùå Unclear relationships
‚ùå Duplicate implementations
‚ùå Hard to navigate

sabot/                    # Stream processing
sabot_sql/                # SQL engine (separate)
sabot_cypher/             # Graph engine (separate)
sabot_ql/                 # SPARQL engine (separate)
MarbleDB/                 # State backend (separate)
```

### After: Unified (Single System)

```
‚úÖ Single entry point (Sabot class)
‚úÖ Clear architecture layers
‚úÖ Shared implementations
‚úÖ Easy to use and extend

sabot/
  ‚îú‚îÄ __init__.py          # Single entry point
  ‚îú‚îÄ engine.py            # Unified engine
  ‚îú‚îÄ operators/           # Central registry
  ‚îú‚îÄ state/               # Unified state management
  ‚îî‚îÄ api/                 # Clean API facades
```

---

## Usage Examples

### Quick Start

```python
from sabot import Sabot

# Create engine
engine = Sabot(mode='local')

# Use any API
stream = engine.stream.from_parquet('data.parquet')
result = engine.sql("SELECT * FROM stream WHERE x > 10")

# Get stats
stats = engine.get_stats()
print(stats)
# {'mode': 'local', 'state_backend': 'MarbleDBBackend', 'operators_registered': 8}
```

### Stream Processing

```python
engine = Sabot()

# Stream API (unchanged interface, unified access)
stream = (engine.stream
    .from_kafka('localhost:9092', 'transactions', 'my-group')
    .filter(lambda b: b.column('amount') > 1000)
    .select('id', 'amount', 'customer_id'))

for batch in stream:
    print(f"Processed {batch.num_rows} rows")
```

### SQL Processing

```python
engine = Sabot()

# Register table
engine.sql.register_table('events', events_table)

# Execute SQL
result = engine.sql('''
    SELECT customer_id, SUM(amount) as total
    FROM events
    WHERE date >= '2025-01-01'
    GROUP BY customer_id
''')
```

### Graph Processing

```python
engine = Sabot()

# Cypher queries
matches = engine.graph.cypher('''
    MATCH (p:Person)-[:KNOWS]->(f:Person)
    WHERE p.age > 25
    RETURN p.name, f.name
''')

# SPARQL queries
triples = engine.graph.sparql('''
    SELECT ?subject ?predicate ?object
    WHERE {
        ?subject ?predicate ?object
    }
    LIMIT 100
''')
```

### Distributed Mode

```python
# Create distributed engine
engine = Sabot(
    mode='distributed',
    coordinator='localhost:8080',
    state_path='./sabot_state'
)

# Same API, distributed execution
stream = engine.stream.from_kafka('topic')
# Automatically uses shuffle service and job manager
```

---

## Architecture Layers

### 1. User API Layer (Python)

**Location:** `sabot/api/`

**Components:**
- `stream_facade.py` - Stream processing
- `sql_facade.py` - SQL processing
- `graph_facade.py` - Graph processing  
- Existing: `stream.py`, `window.py`, `state.py`

**Performance:** Thin wrappers (~10ns overhead)

### 2. Operator Layer (Cython)

**Location:** `sabot/operators/`

**Components:**
- `registry.py` - Central operator registry
- `_cython/aggregations.pyx` - GroupBy, aggregations
- `_cython/joins.pyx` - Hash, AsOf, Interval joins
- `_cython/transform.pyx` - Filter, map, select

**Performance:** Near C++ speed (~1ns overhead)

### 3. State Layer (C++ via Cython)

**Location:** `sabot/state/`

**Components:**
- `interface.py` - StateBackend ABC
- `manager.py` - Auto-selection
- `marble.py` - MarbleDB backend (primary)
- Fallbacks: RocksDB, Redis, Memory

**Performance:** Native C++ (MarbleDB)

### 4. Execution Engines (C++)

**Location:** External projects

**Components:**
- `sabot_sql/` - DuckDB fork
- `sabot_cypher/` - Kuzu fork
- `sabot_ql/` - SPARQL engine
- `MarbleDB/` - State backend

**Performance:** Native C++ performance

---

## Benefits Achieved

### For Users
- ‚úÖ Single `Sabot()` entry point
- ‚úÖ Discoverable API (engine.stream, engine.sql, engine.graph)
- ‚úÖ Consistent experience across APIs
- ‚úÖ Clear documentation

### For Developers
- ‚úÖ Easy to find code (clear layers)
- ‚úÖ Single operator implementation (no duplication)
- ‚úÖ Clean interfaces (easy to extend)
- ‚úÖ Better testability

### For Performance
- ‚úÖ Zero regression (delegates to existing code)
- ‚úÖ Clear performance contracts
- ‚úÖ C++ ‚Üí Cython ‚Üí Python layering enforced
- ‚úÖ Zero-copy Arrow throughout

---

## Testing

**Run tests:**
```bash
python examples/unified_api_simple_test.py
```

**Expected output:**
```
‚úÖ Operator registry imports work
‚úÖ Created default registry with 8 operators
‚úÖ State interface imports work
‚úÖ Engine imports work
‚úÖ Created engine in local mode
‚úÖ Engine shutdown complete
```

**Import test:**
```python
from sabot import Sabot, create_engine
from sabot.operators import get_global_registry
from sabot.state import StateManager

# All imports work ‚úÖ
```

---

## Migration Guide

### From Old API

**Old code:**
```python
from sabot.api.stream import Stream
stream = Stream.from_kafka(...)
```

**New code (preferred):**
```python
from sabot import Sabot
engine = Sabot()
stream = engine.stream.from_kafka(...)
```

**Old code still works!** No breaking changes.

### Adopting Unified API

1. Start new code with `Sabot()` engine
2. Keep old code unchanged
3. Gradually migrate to unified API
4. Deprecation warnings in future versions

---

## What's Next

### Phase 2: Shuffle & Coordinators (Weeks 3-4)
- Unify shuffle system under `sabot/orchestrator/shuffle/`
- Merge 3 coordinators into single JobManager
- Create HTTP API layer

### Phase 3: Windows & Query Layer (Week 5)
- Consolidate window implementations
- Create unified logical plan representation
- Build composability between APIs

### Phase 4-5: C++ Core (Weeks 6-10)
- Create `sabot_core` C++ library
- Move hot-path code to C++ (optimizer, scheduler, shuffle)
- Cython bridges for zero-copy integration

---

## Status

**Phase 1:** ‚úÖ COMPLETE (Unified entry point + operator registry + state interface)  
**Phase 2:** üîÑ In Progress (Shuffle unification + coordinator consolidation)  
**Phase 3:** ‚è≥ Planned (Window consolidation + query layer)  
**Phase 4-5:** ‚è≥ Planned (C++ core library)

---

## Questions?

**"Does old code still work?"**  
‚úÖ Yes! All existing imports and APIs maintained.

**"Is there any performance regression?"**  
‚úÖ No. New code delegates to existing implementations.

**"When can I use the unified API?"**  
‚úÖ Now! Import `from sabot import Sabot` and start using it.

**"What about composing Stream + SQL + Graph?"**  
‚è≥ Coming in Phase 3 with unified query layer.

---

**Documentation:** See `ARCHITECTURE_UNIFICATION_STATUS.md` and `UNIFICATION_COMPLETE_PHASE1.md`  
**Examples:** See `examples/unified_api_simple_test.py`  
**Tests:** `python examples/unified_api_simple_test.py`

---

**Built:** October 18, 2025  
**Version:** 0.1.0-unified-alpha  
**Status:** Phase 1 Complete ‚úÖ

