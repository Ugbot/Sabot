# Sabot Optimization Features - What's in the Toolbox

**Date:** November 14, 2025  
**Status:** Catalog of available optimizations

---

## ðŸ”§ Available Performance Features

### 1. Buffer Pooling (buffer_pool.pyx)

**What it does:**
- Pools buffers by size class (4KB, 64KB, 1MB, 16MB)
- Thread-safe checkout/return
- 50% reduction in allocations
- <100ns allocation (vs 1-10Î¼s for malloc)

**How to use:**
```python
from sabot._cython.arrow.buffer_pool import get_buffer_pool

pool = get_buffer_pool()
buf = pool.get_buffer(64*1024)  # Checkout
# Use buffer...
pool.return_buffer(buf)  # Recycle!
```

**Benefits:**
- 50% fewer allocations
- Better cache locality
- Lower GC pressure

**Current status:** NOT USED in TPC-H queries

### 2. Zero-Copy Buffer Access (zero_copy.pyx)

**What it does:**
- Direct buffer views (<5ns access)
- Eliminates to_numpy() overhead (50-100ns)
- No memory allocation
- SIMD-friendly contiguous memory

**How to use:**
```python
from sabot._cython.arrow.zero_copy import get_int64_buffer

arr = pa.array([1, 2, 3], type=pa.int64())
buf = get_int64_buffer(arr)  # Zero-copy view!
# Direct access: buf[0], buf[1], etc.
```

**Benefits:**
- 10-20x faster buffer access
- No allocations
- Better for tight loops

**Current status:** NOT USED in TPC-H queries

### 3. Memory Pool (memory_pool.pyx)

**What it does:**
- Custom Arrow memory allocator
- Pre-allocated regions
- Reduced fragmentation
- Better for large allocations

**How to use:**
```python
from sabot._cython.arrow.memory_pool import get_memory_pool

pool = get_memory_pool()
# Use with Arrow operations
table = pa.Table.from_batches(batches, memory_pool=pool)
```

**Benefits:**
- Less fragmentation
- Faster allocations
- Better memory locality

**Current status:** NOT USED in TPC-H queries

### 4. Batch Processor (batch_processor.pyx)

**What it does:**
- Optimized batch processing utilities
- Vectorized operations
- Pre-compiled common patterns

**Features:**
- Fast batch filtering
- Efficient column selection
- Optimized transformations

**Current status:** UNKNOWN if used

### 5. Join Processor (join_processor.pyx)

**What it does:**
- Optimized hash join implementation
- Better than Arrow's default
- Memory-efficient hash tables

**Features:**
- Fast hash computation
- Efficient probing
- Buffer reuse

**Current status:** Likely used via CythonHashJoinOperator

### 6. Window Processor (window_processor.pyx)

**What it does:**
- Optimized window operations
- Incremental computation
- Minimal memory overhead

**Features:**
- Sliding window aggregations
- Tumbling windows
- Session windows

**Current status:** NOT USED in TPC-H (no window queries)

### 7. Zero-Copy Optimized (zero_copy_optimized.pyx)

**What it does:**
- Advanced zero-copy techniques
- Buffer sharing
- Minimal data movement

**Current status:** UNKNOWN if used

---

## ðŸš€ What We Should Enable for TPC-H

### High Priority (Big Impact)

**1. BufferPool for aggregations**
- Reuse buffers in GroupBy operations
- Expected: 20-30% faster
- Reduces allocations by 50%

**2. Zero-copy buffer access in tight loops**
- Use in filter predicates
- Use in hash computations
- Expected: 10-20% faster

**3. Memory pool for large operations**
- Use for Table.from_batches()
- Use for large hash tables
- Expected: 10-15% faster

### Already Using (Good!)

**âœ… CythonGroupByOperator** (streaming aggregation)
**âœ… CythonHashJoinOperator** (optimized joins)
**âœ… Parallel I/O** (4-thread reading)
**âœ… Morsel parallelism** (8 workers)
**âœ… CyArrow** (custom SIMD kernels)

### Not Using (Opportunity!)

**âŒ BufferPool** - Easy win, 50% less allocations
**âŒ Zero-copy buffer access** - Fast access in hot paths
**âŒ Memory pool** - Better for large data
**âŒ Batch processor** - Pre-compiled patterns

---

## ðŸŽ¯ Implementation Priority

### Phase 1: BufferPool (Highest Impact)

**Enable in:**
- GroupBy aggregation
- Join operations
- Map/filter operations

**Expected:** 20-30% faster, especially at scale

### Phase 2: Zero-Copy Access

**Enable in:**
- Filter predicates (hot path)
- Hash computations
- Tight loops

**Expected:** 10-20% faster on compute-heavy queries

### Phase 3: Memory Pool

**Enable in:**
- Table.from_batches() calls
- Large allocations
- Hash table creation

**Expected:** 10-15% faster on large data

**Combined: 1.5-2x faster at scale, matching DuckDB!** âœ…

---

## ðŸ’¡ Why These Help Scaling

**At 600K rows:**
- Allocation overhead: Small
- Buffer reuse benefit: Minimal
- Memory pool: Not critical

**At 10M rows:**
- Allocation overhead: HUGE!
- Buffer reuse: 50% reduction critical
- Memory pool: Prevents fragmentation

**These features specifically help at scale!**

---

## âœ¨ Bottom Line

**Sabot HAS the optimizations built:**
- âœ… BufferPool (50% less allocations)
- âœ… Zero-copy access (<5ns)
- âœ… Memory pools (less fragmentation)
- âœ… Optimized processors

**We're just not using them in TPC-H queries!**

**Enabling these could close the 1.5x gap at scale** ðŸš€

---

**Next: Enable BufferPool, zero-copy, and memory pool in Stream API** ðŸ’ª

