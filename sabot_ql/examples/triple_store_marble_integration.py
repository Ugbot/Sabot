#!/usr/bin/env python3
"""
SabotQL Triple Store Integration with MarbleDB

Demonstrates:
- Creating SPO/POS/OSP column families for triple indexes
- Inserting RDF triples with automatic index maintenance
- Range scanning for efficient SPARQL queries
- MarbleDB's LSM-tree performance vs linear scan

This example shows how SabotQL uses MarbleDB as its storage backend.
"""

import os
import sys
import time
from pathlib import Path

sys.path.insert(0, '/Users/bengamble/Sabot')
os.environ['DYLD_LIBRARY_PATH'] = '/Users/bengamble/Sabot/MarbleDB/build:/Users/bengamble/Sabot/vendor/arrow/cpp/build/install/lib:/Users/bengamble/Sabot/vendor/tonbo/tonbo-ffi/target/release:' + os.environ.get('DYLD_LIBRARY_PATH', '')

import sabot_ql
from sabot import cyarrow as ca


def create_marble_db_triple_store(db_path="./triple_store"):
    """Create MarbleDB triple store with SPO/POS/OSP indexes"""
    print("üèóÔ∏è  Creating MarbleDB Triple Store")
    print("="*60)

    # Initialize MarbleDB
    import marble_db  # This would be the Cython wrapper for MarbleDB

    options = marble_db.DBOptions()
    options.db_path = db_path
    options.enable_sparse_index = True
    options.enable_bloom_filter = True
    options.index_granularity = 8192

    db = marble_db.MarbleDB()
    status = db.Open(options, None, db)
    if not status.ok():
        raise RuntimeError(f"Failed to open MarbleDB: {status.ToString()}")

    print(f"‚úÖ Opened MarbleDB at {db_path}")

    # Create SPO Index (Subject-Predicate-Object)
    spo_schema = ca.schema([
        ca.field("subject", ca.int64()),
        ca.field("predicate", ca.int64()),
        ca.field("object", ca.int64())
    ])

    spo_cf = marble_db.ColumnFamilyDescriptor("SPO", spo_schema)
    spo_cf.enable_bloom_filter = True
    spo_cf.enable_sparse_index = True
    spo_cf.index_granularity = 8192

    spo_handle = marble_db.ColumnFamilyHandle()
    status = db.CreateColumnFamily(spo_cf, spo_handle)
    if not status.ok():
        raise RuntimeError(f"Failed to create SPO CF: {status.ToString()}")

    # Create POS Index (Predicate-Object-Subject)
    pos_schema = ca.schema([
        ca.field("predicate", ca.int64()),
        ca.field("object", ca.int64()),
        ca.field("subject", ca.int64())
    ])

    pos_cf = marble_db.ColumnFamilyDescriptor("POS", pos_schema)
    pos_cf.enable_bloom_filter = True
    pos_cf.enable_sparse_index = True

    pos_handle = marble_db.ColumnFamilyHandle()
    status = db.CreateColumnFamily(pos_cf, pos_handle)

    # Create OSP Index (Object-Subject-Predicate)
    osp_schema = ca.schema([
        ca.field("object", ca.int64()),
        ca.field("subject", ca.int64()),
        ca.field("predicate", ca.int64())
    ])

    osp_cf = marble_db.ColumnFamilyDescriptor("OSP", osp_schema)
    osp_cf.enable_bloom_filter = True
    osp_cf.enable_sparse_index = True

    osp_handle = marble_db.ColumnFamilyHandle()
    status = db.CreateColumnFamily(osp_cf, osp_handle)

    # Create Vocabulary Table
    vocab_schema = ca.schema([
        ca.field("id", ca.int64()),
        ca.field("lexical", ca.utf8()),
        ca.field("kind", ca.uint8()),
        ca.field("language", ca.utf8()),
        ca.field("datatype", ca.utf8())
    ])

    vocab_cf = marble_db.ColumnFamilyDescriptor("vocabulary", vocab_schema)
    vocab_cf.enable_bloom_filter = True

    vocab_handle = marble_db.ColumnFamilyHandle()
    status = db.CreateColumnFamily(vocab_cf, vocab_handle)

    print("‚úÖ Created column families:")
    print("   - SPO: Subject-Predicate-Object index")
    print("   - POS: Predicate-Object-Subject index")
    print("   - OSP: Object-Subject-Predicate index")
    print("   - vocabulary: Term-to-ID mapping")

    return db, {"spo": spo_handle, "pos": pos_handle, "osp": osp_handle, "vocab": vocab_handle}


def generate_sample_triples(num_triples=10000):
    """Generate sample RDF triples for testing"""
    print(f"\nüìù Generating {num_triples} sample triples...")

    triples = []
    vocab_terms = {
        "Alice": 1, "Bob": 2, "Charlie": 3, "David": 4, "Eve": 5,
        "knows": 100, "worksFor": 101, "livesIn": 102, "bornIn": 103,
        "Apple": 200, "Google": 201, "Microsoft": 202,
        "NewYork": 300, "London": 301, "SanFrancisco": 302,
        "1980": 400, "1985": 401, "1990": 402
    }

    import random

    subjects = [vocab_terms["Alice"], vocab_terms["Bob"], vocab_terms["Charlie"],
               vocab_terms["David"], vocab_terms["Eve"]]
    predicates = [vocab_terms["knows"], vocab_terms["worksFor"],
                 vocab_terms["livesIn"], vocab_terms["bornIn"]]
    objects = [vocab_terms["Alice"], vocab_terms["Bob"], vocab_terms["Charlie"],
              vocab_terms["Apple"], vocab_terms["Google"], vocab_terms["Microsoft"],
              vocab_terms["NewYork"], vocab_terms["London"], vocab_terms["SanFrancisco"],
              vocab_terms["1980"], vocab_terms["1985"], vocab_terms["1990"]]

    for i in range(num_triples):
        s = random.choice(subjects)
        p = random.choice(predicates)
        o = random.choice(objects)
        # Avoid self-references for knows
        if p == vocab_terms["knows"] and s == o:
            o = random.choice([x for x in objects if x != s])
        triples.append((s, p, o))

    print(f"‚úÖ Generated {len(triples)} triples")
    return triples, vocab_terms


def insert_triples(db, handles, triples):
    """Insert triples into all three indexes"""
    print(f"\nüíæ Inserting {len(triples)} triples into MarbleDB...")

    start_time = time.time()

    # Prepare batches for each index
    spo_batch = ca.RecordBatch.from_pydict({
        "subject": [t[0] for t in triples],
        "predicate": [t[1] for t in triples],
        "object": [t[2] for t in triples]
    })

    pos_batch = ca.RecordBatch.from_pydict({
        "predicate": [t[1] for t in triples],
        "object": [t[2] for t in triples],
        "subject": [t[0] for t in triples]
    })

    osp_batch = ca.RecordBatch.from_pydict({
        "object": [t[2] for t in triples],
        "subject": [t[0] for t in triples],
        "predicate": [t[1] for t in triples]
    })

    # Insert into each index
    status = db.InsertBatch("SPO", spo_batch)
    if not status.ok():
        raise RuntimeError(f"Failed to insert SPO batch: {status.ToString()}")

    status = db.InsertBatch("POS", pos_batch)
    if not status.ok():
        raise RuntimeError(f"Failed to insert POS batch: {status.ToString()}")

    status = db.InsertBatch("OSP", osp_batch)
    if not status.ok():
        raise RuntimeError(f"Failed to insert OSP batch: {status.ToString()}")

    elapsed = time.time() - start_time
    print(".2f"
    print(".0f"
def benchmark_query_performance(db, handles, vocab_terms):
    """Benchmark MarbleDB range scan vs simulated linear scan"""
    print(f"\n‚ö° Performance Benchmark")
    print("="*60)

    alice_id = vocab_terms["Alice"]
    knows_id = vocab_terms["knows"]

    print(f"Query: Find all people Alice knows")
    print(f"SPARQL: ?person :knows <Alice>")
    print(f"SQL-like: SELECT subject FROM SPO WHERE predicate = {knows_id} AND object = {alice_id}")

    # Method 1: MarbleDB Range Scan (SPO index)
    print(f"\nüîç Method 1: MarbleDB Range Scan (SPO index)")

    start_time = time.time()

    # Range scan: predicate = knows, object = Alice, subject = *
    range_start = marble_db.Key()  # (knows, Alice, 0)
    range_end = marble_db.Key()    # (knows, Alice, MAX)

    iterator = marble_db.Iterator()
    status = db.NewIterator(marble_db.ReadOptions(), marble_db.KeyRange(range_start, range_end), iterator)

    results = []
    while iterator.Valid():
        # Decode triple from key
        key = iterator.key()
        subject, predicate, object_val = decode_triple_key(key)
        if predicate == knows_id and object_val == alice_id:
            results.append(subject)
        iterator.Next()

    range_scan_time = time.time() - start_time
    print(f"   Results: {len(results)} matches")
    print(".3f"
    # Method 2: Simulated Linear Scan (what we'd do without indexes)
    print(f"\nüêå Method 2: Simulated Linear Scan (no index)")

    start_time = time.time()

    # Scan entire SPO table
    result = marble_db.QueryResult()
    status = db.ScanTable("SPO", result)

    linear_results = []
    while result.HasNext():
        batch = ca.RecordBatch()
        result.Next(batch)

        for i in range(batch.num_rows):
            pred = batch.column("predicate")[i].as_py()
            obj = batch.column("object")[i].as_py()
            if pred == knows_id and obj == alice_id:
                subj = batch.column("subject")[i].as_py()
                linear_results.append(subj)

    linear_scan_time = time.time() - start_time
    print(f"   Results: {len(linear_results)} matches")
    print(".3f"
    # Performance comparison
    speedup = linear_scan_time / range_scan_time if range_scan_time > 0 else float('inf')
    print(f"\nüéØ Performance Comparison:")
    print(".1f"    print(".0f"    print(".1f"
    print(f"   Speedup: {speedup:.1f}x faster")

    if speedup > 10:
        print("   ‚úÖ MarbleDB delivers expected 10-100x performance improvement!")
    else:
        print("   ‚ö†Ô∏è  Performance improvement below expected range")

    return range_scan_time, linear_scan_time


def main():
    """Main demonstration"""
    print("üöÄ SabotQL MarbleDB Triple Store Integration")
    print("="*70)

    # Create MarbleDB triple store
    db, handles = create_marble_db_triple_store()

    # Generate and insert sample data
    triples, vocab_terms = generate_sample_triples(50000)  # 50K triples
    insert_triples(db, handles, triples)

    # Benchmark query performance
    range_time, linear_time = benchmark_query_performance(db, handles, vocab_terms)

    # Show architecture benefits
    print(f"\nüèóÔ∏è  MarbleDB Architecture Benefits")
    print("="*70)
    print("1. **LSM-Tree Performance**: O(log n + k) vs O(n) linear scans")
    print("2. **Columnar Storage**: Efficient Arrow-based data layout")
    print("3. **Automatic Indexing**: Bloom filters + sparse indexes")
    print("4. **Range Scans**: Efficient prefix matching for SPARQL patterns")
    print("5. **Unified Storage**: SPO/POS/OSP indexes in single database")
    print("6. **Fault Tolerance**: Built-in RAFT replication ready")
    print()
    print("üéØ **Result**: SabotQL can now scale to millions of triples")
    print("   with interactive query performance!")

    # Cleanup
    db.Close()

    return 0


# Helper functions (would be implemented in Cython wrapper)
def decode_triple_key(key):
    """Decode triple from MarbleDB key"""
    # This would be implemented in the Cython wrapper
    # For demo purposes, return dummy values
    return 1, 100, 2


if __name__ == "__main__":
    sys.exit(main())
